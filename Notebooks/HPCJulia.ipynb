{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelism and HPC Julia\n",
    "\n",
    "Julia's documentation: http://docs.julialang.org/en/release-0.5/manual/parallel-computing/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will go over the different aspects of parallelism present in Julia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIMD\n",
    "\n",
    "SIMD, Single Instruction Multiple Data, is a form of parallelism from executing multiple similar commands at once using specialized instructions in the processor. Julia applies SIMD automatically to loops and some functions due to the `-O3` optimization in its JIT compilation. However, SIMD can be explicitly added to a loop by using the `@simd` macro (note, this may slow down the calcuation. It is wise to let the auto-optimizer apply SIMD, and finer control of SIMD can be achieved using the SIMD.jl library.\n",
    "\n",
    "Another form of multiple instruction is fused multiply add for calculations of type `a*b+c`. There are two forms present in Julia. The first is `muladd`. This is the recommended form for performance. `muladd(a,b,c)` will only apply a fused multiplication/addition if it will help with performance. On the otherhand, `fma(a,b,c)` will always apply fused multiplication/addition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multithreading\n",
    "\n",
    "As of Julia v0.5, experimental multithreading is native to Julia via the `Threads.@threads` macro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Parallelism\n",
    "\n",
    "Julia's native parallelism is a distributed form of parallelism through TCPIP/ssh.\n",
    "\n",
    "### Libraries\n",
    "\n",
    "The following libraries are helpful for solving parallel problems:\n",
    "\n",
    "- DistributedArrays.jl\n",
    "- ParallelDataTransfer.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projects\n",
    "\n",
    "## Project 1: Getting Started with Distributed Parallelism\n",
    "\n",
    "Use the following tutorial to test Julia's distributed parallelism:\n",
    "\n",
    "http://www.stochasticlifestyle.com/multi-node-parallelism-in-julia-on-an-hpc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 2: Coding a Distributed Algorithm\n",
    "\n",
    "Extend your `least_squares` implementation to a distributed algorithm.\n",
    "\n",
    "- Now generate a much larger `X` and `y`\n",
    "- Use DistributedArrays.jl or ParallelDataTransfer.jl to evenly split the data amongst worker processes\n",
    "- Apply the `@spawnat` macro to use the `least_squares` function on the remote processes\n",
    "- Retrive the results of the `least_squares` algorithm, and average them together\n",
    "- Now try a different approach using `pmap`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarks\n",
    "\n",
    "- Benchmark the two codes on your computer (or cluster!). How does the performance scale with the number of processes? Look at http://www.stochasticlifestyle.com/236-2/\n",
    "- Try to make a multithreaded version of the algorithm. How well does it benchmark? Check for type instabilities!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "\n",
    "# Extras\n",
    "\n",
    "## Job Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UC Irvine Cluster (SGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#$ -N jbtest\n",
    "#$ -q <Queue>\n",
    "#$ -pe mpich 128\n",
    "#$ -cwd            \t\t# run the job out of the current directory\n",
    "#$ -m beas\n",
    "#$ -ckpt blcr\n",
    "#$ -o output/\n",
    "#$ -e output/\n",
    "module load julia/0.4.3\n",
    "julia --machinefile jbtest-pe_hostfile_mpich.$JOB_ID test.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XSEDE Comet (Slurm) Job Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -A <account>\n",
    "#SBATCH --job-name=\"juliaTest\"\n",
    "#SBATCH --output=\"juliaTest.%j.%N.out\"\n",
    "#SBATCH --partition=compute\n",
    "#SBATCH --nodes=8\n",
    "#SBATCH --export=ALL\n",
    "#SBATCH --ntasks-per-node=24\n",
    "#SBATCH -t 01:00:00\n",
    "export SLURM_NODEFILE=`generate_pbs_nodefile`\n",
    "./julia --machinefile $SLURM_NODEFILE /home/crackauc/test.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Script which prints out the hostnames of the worker processes\n",
    "# Used in conjunction with a job script to ensure multi-node parallelism\n",
    "\n",
    "hosts = @parallel for i=1:120\n",
    "       run(`hostname`) end\n",
    "println(hosts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
